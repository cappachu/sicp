
#lang planet neil/sicp

1.1.3 Evaluating Combinations - pg 9
------------------------------------
Evaluating Combinations - recursive
percolate values upwards: tree accumulation

Environment: context in which evaluation takes place

define is not a combination, it's a special form which has its own evaluation rule

1.1.4 Compound Procedures - pg 11
---------------------------------
???
parameters: names used within body of procedure
operands: the things being operated on 
arguments: values of operands

(define (<name> <formal parameters>) <body>)

1.1.5 Substitution Model for Procedure Application - pg 13
----------------------------------------------------------

- evaluate elements of combination and applies procedure (value of operator) to the arguments (values of oeprands).

- compound procedure: evaluate body of procedure with formal parameters replaced by corresponding arguments.

substitution model example:
1) (square 5)
2) body of square:
   (* x x)
3) replace formal parameter x with argument 5
   (* 5 5)

- substitution model - is a thinking model not how the interpreter actually works ("substitution" is actually accomplished by using a local environment for the formal parameters)

- substitution model (an incomplete model) will be replaced by more refined models later

Applicative order versus normal order pg 15
-------------------------------------------

- NORMAL ORDER EVALUTION: fully expand (till you reach only primitives) and then reduce (evaluate operands until their values are needed)

- APPLICATIVE ORDER EVALUATION: evaluate arguments then apply (interpreter actually uses this, which avoids multiple evaluations of the same expressions - example provided in this section, and becauses its easier to deal with procedures that can not be modelled by substitution)

- for procedures that can be modelled using substitution (chapters 1 and 2) and yield legitimate values normal-order and applicative-order produces the same values (see exercise 1.5 for illegitimate value example that does not produce the same result)

1.1.6 Conditional Expressions and Predicates pg 17
--------------------------------------------------

cond for case analysis (CONDitional)
clauses (<pn> <en>) consist of predicates and consequent expressions

(cond (<p1> <e1>)
	  (<p2> <e2>)
	  .
	  .
	  (<pn> <en>))

returns the consquent expression <e> corresponding to the first true predicate <p>
if none of the <p>'s evaluate to true the cond is undefined

"else" just evaluates to true or #t - could use anything that evaluates to true

(if <predicate> <consequent> <alternate>)

"and" and "or" are special forms since all subexpressions are not always evaluated.

A difference between "if" and "cond" is that the <e>'s in the cond can be a sequance of expressions

example:
(cond (#t (display 'hi) (display 'thre') 4)
	  (#f 6))

(cond (#t (display 'hi) 4 3)
        (#f 2))

Logical Operators:
"and" and "or" are special forms since not all subexpressions are evaluated

; sum of square of the larger two numbers
(define (larger x y)
    (if (> x y) x y))

(define (sum-square-larger-pair x y z)
  (if (= x (larger x y))
      (sum-of-squares x (larger y z))
      (sum-of-squares y (larger x z))))



1.1.7 Example: Square Roots by Newton's Method pg 21
----------------------------------------------------

Declarative (what is) VS Imperative (how to)

Square roots with Newton's method (the general technique) 
or Heron of Alexandria 1st Century A.D.


; NOTE: 
; - recursive call to sqrt-iter with improved guess
; - we can write any purely numerical program using just procedure calls (without any iterative looping constructs!)

(define (sqrt-iter guess x)
  (if (good-enough? guess x)
      guess
      (sqrt-iter (improve guess x) x)))

; NOTE: good-enough? is not effective for finding square roots of very small or very large numbers because of limited precision arithmetic on most computers. A better way might be to watch how guess changes through each iteration as a proportion of the itself. (delta guess / guess)
(define (good-enough? guess x)
  (< (abs (- (square guess) x)) 0.0001))

(define (improve guess x)
  (avg guess (/ x guess))) 

(define (avg x y)
  (/ (+ x y) 2))

; NOTE: mixed operations on decimals and rationals yield decimals. 
(define (sqrt x)
    (sqrt-iter 1.0 x))


1.1.8 Procedures as Black Box Abstractions pg 26
------------------------------------------------

Local names pg 27
-----------------
The meaning of a procedure should be independent of the parameter names used by its author, i.e. the following two procedures should be indistinguishable:

(define (square x) (* x x))

(define (sqyare y) (* y y))

A procedure binds its formal parameters, these are called bound variables. An unbound variable is "free".

scope: the set of expressions for which a binding defines a name.

(define (good-enough? guess x)
  (< (abs (- (square guess) x)) 0.001))

In the definition above guess and x are bound but <, -, abs, square are free. The definition of good-enough? is independent of its bound variables and not independent of its free variables.

Internal definitions and block structure pg 30
----------------------------------------------

NOTE: nesting definitions is one solution to the name-packaging problem (so names of sub procedures do not pollute the name space)

;; Block-structured
(define (sqrt x)
  (define (good-enough? guess x)
    (< (abs (- (square guess) x)) 0.001))
  (define (improve guess x)
    (average guess (/ x guess)))
  (define (sqrt-iter guess x)
    (if (good-enough? guess x)
        guess
        (sqrt-iter (improve guess x) x)))
  (sqrt-iter 1.0 x))


NOTE: But we can go further by allowing x to be a free variable in the internal definitions. This is called LEXICAL SCOPING: free variabls in a procedure refer to bindings made by enclosing procedure definitions; that is they are looked up in the environment in which the procedure was defined.

;; Taking advantage of lexical scoping
(define (sqrt x)
  (define (good-enough? guess)
    (< (abs (- (square guess) x)) 0.001))
  (define (improve guess)
    (average guess (/ x guess)))
  (define (sqrt-iter guess)
    (if (good-enough? guess)
        guess
        (sqrt-iter (improve guess))))
  (sqrt-iter 1.0))


1.2 Procedures and the Processes they Generate pg 31
----------------------------------------------------

Linear Recursion and Iteration
------------------------------
;; Recursive

NOTE:
- recursive procedure
- recursive process

(define (factorial n)
  (if (= n 1)
      1
      (* n (factorial (- n 1)))))


;; Iterative 

NOTE: 
- recursive procedure
- iterative process 

(define (factorial n)
  (fact-iter 1 1 n))

(define (fact-iter product counter max-count)
  (if (> counter max-count)
      product
      (fact-iter (* counter product)
                 (+ counter 1)
                 max-count)))

;; Iterative, block-structured (from footnote)

(define (factorial n)
  (define (iter product counter)
    (if (> counter n)
        product
        (iter (* counter product)
              (+ counter 1))))
  (iter 1 1))


LINEAR RECURSIVE PROCESS: expand then contract deferred operations. The interpreter keeps track of operations to be performed. The length of the chain of DEFERRED OPERATIONS and hence the INFORMATION requred to be kept GROWS LINEARLY. (see shape diagram on pg 34)

LINEAR ITERATIVE PROCESS: iterative processes are those that can be modeled by STATE VARIABLES and RULES of how to update the state variables. NO. OF STEPS GROWS LINEARLY.
- program variables provide complete description of process state (easy to resume, not so with recursive)

NOTE: distinction between recursive PROCESS (how the process evolves) and recursive PROCEDURE (syntactically refers to itself directly or indirectly) .

TAIL RECURSIVE: tail recursive implementations of interpreters are capable of using constant memory space for iterative processes even if they are defined by recursive procedures. (Most implementations of C, C++ are incapable of this, they instead use special looping constructs like do, repeat, until, for, and while to describe iterative processes).

* footnote on pg 36 points to a paper on tail recursion by Carl Hewitt (1977) as inspiration for Scheme's tail recursion

Exercise 1.9 pg 36
------------------
linear recursive process - deferred operations

(+ 4 5)
(inc (+ 3 5))
(inc (inc (+ 2 5)))
(inc (inc (inc (+ 1 5))))
(inc (inc (inc (inc (+ 0 5)))))
(inc (inc (inc (inc 5))))
(inc (inc (inc 6)))
(inc (inc 7))
(inc 8)
9

linear iterative process - captured by state variables

(+ 4 5)
(+ 3 6)
(+ 2 7)
(+ 1 8)
(+ 0 9)
9

1.2.2 Tree Recursion pg 37 (as opposed to Linear Recursive Process)
--------------------------

Tree Recursive Process in General:
- STEPS required 0(No. nodes in Tree) 
- SPACE required 0(max depth of Tree) 

Terribly inefficient Fib
- number of steps grows exponentially 
- exponential O(Fib(n)) or O(phi^n)
- fib 1 and fib 0 are called fib(n+1) times (exponential)
- space grows linearly O(n) 
REVIEW how is n the max depth of the tree?


(define (fib n)
  (cond ((= n 1) 1)
        ((= n 0) 0)
        (else (+ (fib (- n 1))
                 (fib (- n 2))))))

fib calls itself twice each time it is invoked - this causes the process to evolve like a tree.                 

; Iterative Fib
; steps required is linear MUCH MUCH LESS than tree recursive version even for small inputs

updating state variables
a <-- a + b
b <-- a

(define (fib-3 n)
  (define (fib-iter a b count)
    (if (= count 0)
        b
        (fib-iter (+ a b) a (- count 1))))
  (fib-iter 1 0 n))

Tree Recursive Processes are not useless however - they are a natural and powerful tool when operating on hierarchical structured data (the interpreter itself evaluates expressions using a tree-recursive process).

Example: Counting Change pg 40
------------------------------
REVIEW

Exercise 1.11 (REVIEW)
-------------
; Exercise 1.11

; recursive
(define (f n)
  (if (< n 3)
      n
      (+ (f (- n 1))
         (* 2 (f (- n 2)))
         (* 3 (f (- n 3))))))

; iterative 
(define (f-2 n)
  (define (f-iter a b c count)
    (if (= count 2)
        a
        (f-iter (+ a (* 2 b) (* 3 c))
                a
                b
                (dec count))))
  (f-iter 2 1 0 n))

; 1.12 Pascal's Triangle
;
;     1
;    1 1
;   1 2 1
;  1 3 3 1
; 1 4 6 4 1
;
; indices are 1-based
;
(define (pascal-element row col)
  (cond ((and (= row 1) (= col 1)) 1)
        ((or (< col 1) (> col row)) 0)
        (else (+ (pascal-element (dec row) (dec col))
                 (pascal-element (dec row) col)))))



1.2.3 Orders of Growth pg 42
----------------------------

Gross measure resources (R) required

R(n) has order of growth 0(f(n))
R(n) = 0(f(n)) - theta of f(n)

k1 f(n) <= R(n) <= k2 f(n) [for sufficiently large n]

It's a crude measure, for instance a process requiring n^2 steps and one requiring 1000n^2 steps and one requiring 3n^2 + 10n + 17 steps all have order of growth 0(n^2)

But it does provide an indication of how the resource usage changes as we change the size of the problem.

linear 0(n): 
double n -> double resources 
n -> 2n
r -> 2r

exponential 0(c^n):
n -> n + 1
r -> K * r

logarithmic 0(log(n)):
n -> 2n         
r -> K + r  (log2k = log2 + logk)

; Exercise 1.14
REVIEW

; Exercise 1.15
; a. 5 times, since 12.15/3^5 < 0.1
; b. steps -> 0(log(a))
;    space -> 0(log(a))

1.2.4 Exponentiation pg 44
--------------------------

; Exercise 1.19 pg 47
; a'  = bq + aq + ap
; b'  = bp + aq
; a'' = b'q + a'q + a'p
; b'' = b'p + a'q
;
; a'' = (bp + aq)q +
;       (bq + aq + ap)q +
;       (bq + aq + ap)p
;     = bpq + aq2 +
;       bq2 + aq2 + apq +
;       bqp + aqp + ap2
;     = b(2pq + q2) + 
;       a(2pq + q2) +
;       a(p2  + q2)
;       (which is of the required form)
;
; b'' = (bp + aq)p + 
;       (ba + aq + ap)q
;     = bp2 + aqp +
;       bq2 + aq2 + apq
;     = b(p2 + q2) +
;       a(2pq + q2)
;       (which is of the required form)
; 
; so,    p' = p2 + q2
; and    q' = 2pq + q2
;
; Computing Fibonacci numbers in log(n) steps
; using successive squaring of Transformation Tpq
; read pg 47
(define (fib-log n)
  (fib-log-iter 1 0 0 1 n))

(define (fib-log-iter a b p q count)
  (cond ((= count 0) b)
        ((even? count)
         (fib-log-iter a
                       b
                       (+ (* p p) (* q q))
                       (+ (* 2 p q) (* q q))
                       (/ count 2)))
        (else (fib-log-iter (+ (* b q) (* a q) (* a p))
                            (+ (* b p) (* a q))
                            p
                            q
                            (- count 1)))))

1.2.5 Greatest Common Divisors pg 48
------------------------------------

; Euclid's Algorithm for GCD - oldest 'algorithm'
If r is the remainder when a is divided by b then the common divisors of a and b are the common divisors of b and r

; 0(log(n))

(define (gcd a b)
    (if (= b 0) 
        a
        (gcd b (remainder a b))))

; Exercise 1.20 pg 49
; normal order: certainly more than 4
;(gcd 206 40)
;(if (= 40 0) )
;(gcd 40 (reminder 206 40))
;(if (= (remainder 206 50) 0) )
;(if (= 6 0))
;(gcd (remainder 206 40) (reaminder 40 (remainder 206 40))
;.
;.
;.

; applicative order: 4 calls to remainder
;(gcd 206 40)
;(gcd 40 (remainder 206 40)) 
;(gcd 40 6) 
;(gcd 6 (remainder 40 6)) 
;(gcd 6 4) 
;(gcd 4 (remainder 6 4)) 
;(gcd 4 2) 
;(gcd 2 (remainder 4 2)) 
;(gcd 2 0) 

1.2.6 Example: Testing for Primality pg 50
------------------------------------------

Searching for divisors
----------------------
; 0(sqrt(n))

(define (smallest-divisor n)
  (find-divisor n 2))

(define (find-divisor n test-divisor)
  ; NOTES:
  ; if n is not prime it must have a divisor <= sqrt(n)
  ; because if d is a divisor of n, then so is n/d.
  ; but d and n/d cannot both be greater than n
  (cond ((> (square test-divisor) n) n)
        ((divides? test-divisor n) test-divisor)
        (else (find-divisor n (+ test-divisor 1)))))

(define (divides? a b)
  (= (remainder b a) 0))

(define (prime? n)
  (= n (smallest-divisor n)))

The Fermat test pg 51
---------------------
A PROBABILISTIC Algorithm for primality testing based on Fermat's Little Theorem.

Fermat's Little Theorem: if n is prime then a^n congruent to a modulo n (for a < n). (i.e. a^n mod n = a)

If n is not prime MOST numbers a < n will not satisfy fermats little theorem (pg 51). So we pick a random number a < n and compute the remainder a^n mod n if the result is not a then n is not prime, if it is a then it is LIKELY prime.

; The Fermat test (probabilistic primality algorithm)
; compute exponential of a number modulo another
; uses successive squaring idea used in fast-expt in 
; section 1.2.4 so num steps are order log(n)
;     
(define (expmod base exp m)
  (cond ((= exp 0) 1) ; anything to the power 0 is 1
        ((even? exp)
         (remainder (square (expmod base (/ exp 2) m))
                    m))
        (else
         (remainder (* base (expmod base (- exp 1) m))
                    m))))        

(define (fermat-test n)
  (define (try-it a)
    (= (expmod a n n) a))
  (try-it (+ 1 (random (- n 1)))))

; runs and tests 'times' number of times
(define (fast-prime? n times)
  (cond ((= times 0) true)
        ((fermat-test n) (fast-prime? n (- times 1)))
        (else false)))

NOTE: We can make the probability of error AS SMALL AS WE LIKE. Algorithms for which we can prove the chance of error can be made ARBITRARILY small are called PROBABILISTIC ALGORITHMS.

; Exercise 1.22 pg 54

(define (timed-prime-test n)
  (newline)
  (display n)
  (start-prime-test n (runtime)))

(define (start-prime-test n start-time)
  (if (prime? n)
      (report-prime (- (runtime) start-time))))

(define (report-prime elapsed-time)
  (display " *** ")
  (display elapsed-time))

(define (search-for-primes start end)
  (cond ((> start end) (newline) 
                       (display "search complete"))
        ((odd? start)(timed-prime-test start)
                     (search-for-primes (+ start 2) end))
        (else (search-for-primes (+ start 1) end))))

;(search-for-primes 1000 1020)
;1009 *** 7
;1013 *** 7
;1019 *** 6
;
;(search-for-primes 10000 10040)
;10007 *** 15
;10009 *** 14
;10037 *** 13
;
;(search-for-primes 100000 100050)
;100003 *** 37
;100019 *** 35
;100043 *** 35
;
;(search-for-primes 1000000 1000040)
;1000003 *** 106
;1000033 *** 97
;1000037 *** 97
;
; As n grows larger the steps correspond closer to the
; 0(sqrt(n)) order of growth, 35 * sqrt(10) -= 97

; Exercise 1.24 pg 55

; redefine timed prime test to use fast-prime? procedure


(define (search-for-primes-fast start end)
  (define (timed-fast-prime-test n)
    (newline)
    (display n)
    (start-prime-test n (runtime)))

  (define (start-prime-test n start-time)
    (if (prime? n)
        (report-prime (- (runtime) start-time))))

  (define (report-prime elapsed-time)
    (display " *** ")
    (display elapsed-time))
  
  (cond ((> start end) (newline) 
                       (display "search complete"))
        ((odd? start)(timed-fast-prime-test start)
                     (search-for-primes-fast (+ start 2) end))
        (else (search-for-primes-fast (+ start 1) end))))

; These take twice as long if run independantly rather
; than within the search-for-primes
;(timed-prime-test 1009)
;(timed-fast-prime-test 1009)

;(search-for-primes-fast 1000 1020)
;1009 *** 7
;1013 *** 7
;1019 *** 6
;
;
;(search-for-primes-fast 10000 10040)
;10007 *** 14
;10009 *** 14
;10037 *** 14
;
;(search-for-primes-fast 100000 100050)
;100003 *** 33
;100019 *** 33
;100043 *** 33
;
;(search-for-primes-fast 1000000 1000040)
;1000003 *** 97
;1000033 *** 97
;1000037 *** 97
;
; Perhaps we have to use much larger numbers to see a difference
; in computation time between prime? and fast-prime?

Exercise 1.26 pg 55
-------------------
Using the substitution model and applicative order evaluation Louis expmod procedure does not cull any multiplications. The correct procedure calls square on the result of expmod which avoids repeating the computations in expmod. Louis procedure creates a tree recursive process - the steps are on the order of 0(num nodes in tree) which grows exponentially with with the depth of the tree = log(n). e^logn = n. so it turns into a procedure that takes on the order of 0(n) steps.

1.3 Formulating Abstractions with Higher-Order Procedures pg 56
---------------------------------------------------------------
High Order Procedures : procedures that manipulate procedures.

1.3.1 Procedures as Arguments pg 57
-----------------------------------

; 1.3.1 Procedures as Arguments pg 57
; term : procedure that computes a term to be added
; next : procedure that computes the next value of a
(define (sum term a next b)
  (if (> a b)
      0
      (+ (term a) 
         (sum term (next a) next b))))

(define (cube x) (* x x x))

(define (sum-cubes a b)
  (sum cube a inc b))

(define (identity x) x)

(define (sum-integers a b)
  (sum identity a inc b))

(define (pi-sum a b)
  (define (pi-term x)
    (/ 1.0 (* x (+ x 2))))
  (define (pi-next x)
    (+ x 4))
  (sum pi-term a pi-next b))

(define (approx-pi)
  (* 8 (pi-sum 1 1000)))

(define (integral f a b dx)
  (define (add-dx x) (+ x dx))
  (* (sum f (+ a (/ dx 2.0)) add-dx b)
     dx))

;(integral cube 0 1 0.01)
; 0.24998750000000042
;(integral cube 0 1 0.001)
; 0.249999875000001
; actual value of integral between 0 and 1 is 1/4

; Exercise 1.30 pg 60

(define (sum-iter term a next b)
  (define (iter a result)
    (if (> a b)
        result
        (iter (next a) (+ (term a) result))))
  (iter a 0))


; Exercise 1.31 pg 60

; generates linear recursive process
(define (product term a next b)
  (if (> a b)
      1
      (* (term a)
         (product term (next a) next b))))

; generates linear iterative process
(define (product-iter term a next b)
  (define (iter a result)
    (if (> a b)
        result
        (iter (next a) (* (term a) result))))
  (iter a 1))

(define (factorial-product n)
  (product-iter identity 1 inc n))

(define (approx-pi-product)
  (define (pi-term n)
    (if (even? n)
        (/ (+ n 2) (+ n 1))
        (/ (+ n 1) (+ n 2))))
  (* 4.0 (product-iter pi-term 1 inc 1000)))  

; Exercise 1.32

(define (accumulate combiner null-value term a next b)
  (if (> a b)
      null-value
      (combiner (term a)
                (accumulate combiner null-value term (next a) next b))))

(define (accumulate-iter combiner null-value term a next b)
  (define (iter a result)
    (if (> a b)
        result
        (iter (next a) (combiner (term a) result))))
  (iter a null-value))

(define (sum-accumulate term a next b)
  (accumulate-iter + 0 term a next b))

(define (product-accumulate term a next b)
  (accumulate-iter * 1 term a next b))

1.3.2 Constructing Procedures Using Lambda pg 62
------------------------------------------------

(lambda (<formal-parameters>) <body>)

Just like define without the name. 

(define (plus4 x) (+ x 4))

Equivalent define would be:

(define plus4 (lambda (x) (+ x 4)))

(lambda          (x)                  (+ x 4))
  |               |                    |
("the procedure" ("of an argument x") ("that adds x and 4")

Can use lambda direclty in a combination (just like any expression who's value is a procedure):

((lambda (x y z) (+ x y (square z))) 1 2 3)

or anywhere we would use a procedure name.

NOTE: lambda could have been suitably called "make-procedure". The name lambda comes from the mathematical logician Alonzo Church's lambda calculus (1941) a means to study function and function application.


Using let to create local variables pg 63  
-----------------------------------------

(define (f x y)
  (define (f-helper a b)
    (+ (* x (square a))
       (* y b)
       (* a b)))
  (f-helper (+ 1 (* x y))
            (- 1 y)))

Using lambda instead of define to bind local variables:

(define (f x y)
  ((lambda (a b)
     (+ (* x (square a))
        (* y b)
        (* a b)))
   (+ 1 (* x y))
   (- 1 y)))

This is so useful that the special form let makes this more convenient:

(define (f x y)
  (let ((a (+ 1 (* x y)))
        (b (- 1 y)))
    (+ (* x (square a))
       (* y b)
       (* a b))))

let is a special form built via lambda.

(let ((<var1> <exp1>)
      (<var2> <exp2>)
      .
      .
      (<varn> <expn>))
  <body>)

read like so:

let <var1> have the value <exp1> and
    <var2> have the value <exp2> and 
    .
    .
in <body>

SYNTACTIC SUGAR for the lambda:

((lambda (<var1> ... <varn>)
    <body>)
  <exp1>
  .
  .
  .
  <expn>)

Let allows binding of variables as locally as possible.

Note: the variable's values are computed outside the let. i.e. <exp1> will refer to a name outside the scope of the let. For example if x is 2, the following evaluates to 12:
(let ((x 3)        --> x is 3
      (y (+ x 2))) --> y is 4 (outer x + 2)      
   (* x y))

Use let instead of internal defines unless the internal defines bind procedures.

; Exercise 1.34

(define (f g)
  (g 2))

(f square) -> 4

(f (lambda (z) (* z (+ z 1)))) -> 6

Evaluating (f f):
(f f)
(f 2)
(2 2) -> error 2 is not a procedure


1.3.3 Procedures as General Methods pg 66
-----------------------------------------

Finding roots of equations by the half-interval method pg 67
------------------------------------------------------------

half-interval method: if f(a) < 0 < f(b), then f must have atleast one zero between a and b.

If x is the midpoint between a and b and f is continuous then:
if f(x) > 0 then f must have a zero between a and x
if f(x) < 0 then f must have a zero between x and b
We can get smaller and smaller intervals for which f must have a zero.
Stop when interval is small enough.

0(log n) since the interval is reduced by half at each step.


(define (search f neg-point pos-point)
  (let ((midpoint (average neg-point pos-point)))
    (if (close-enough? neg-point pos-point)
        midpoint
        (let ((test-value (f midpoint)))
          (cond ((positive? test-value)
                 (search f neg-point midpoint))
                ((negative? test-value)
                 (search f midpoint pos-point))
                (else midpoint))))))

(define (close-enough? x y)
  (< abs(- x y) 0.001))

; We use a wrapper because search should't be called with two points with the same sign
; the half-interval method doesn't work.

(define (half-interval-method f a b)
  (let ((a-value (f a))
        (b-value (f b)))
    (cond ((and (negative? a-value) (positive? b-value))
           (search f a b))
          ((and (positive? a-value) (negative? b-value))
           (search f b a))
          (else
           (error "Values are not of opposite sign" a b)))))

Finding fixed points of functions pg 68
---------------------------------------

Fixed Point: x is fixed point of a function f if f(x) = x

One way to locate a fixed point of a functions is to begin with an initial guess and apply f repeatedly until the value does not change very much (this works for some functions)

(define tolerance 0.00001)

(define (fixed-point f first-guess)
  (define (close-enough? v1 v2)
    (< (abs (- v1 v2)) tolerance))
  (define (try guess)
    (let ((next (f guess)))
      (if (close-enough? guess next)
          next
          (try next))))
  (try first-guess))


The following procedure does not converge, creating an infinte loop, bouncing back and forth between two guesses:

(define (sqrt-fp x)
  (fixed-point (lambda (y) (/ x y))
                1.0))

One way to prevent the oscillations is to prevent the guess from changing so much.

(define (sqrt-fp-2 x)
  (fixed-point (lambda (y) average y (/ x y))))

Tis approach of averaging successsive approximations to a solution called AVERAGE DAMPING often aids the convergence of fixed-point searches.

; Exercise 1.35 pg 70
; 
; 1 + 1/phi
; = (phi + 1) / phi
; = phi^2 / phi [since phi^2 = phi + 1 (page 38)]
; = phi
;
(define tolerance 0.00001)

(define (fixed-point f first-guess)
  (define (close-enough? v1 v2)
    (< (abs (- v1 v2)) tolerance))
  (define (try guess)
    (let ((next (f guess)))
      (if (close-enough? guess next)
          next
          (try next))))
  (try first-guess))
  
(define (golden-ratio)
  (fixed-point (lambda (x) (+ 1 (/ 1 x)))
               1.0))

























---- pg 61 -----


















